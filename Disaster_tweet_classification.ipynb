{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaster Tweet Classification with tinyBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In recent years, Twitter, now called X, has emerged as a vital communication platform during emergencies, allowing users to share real-time updates about crises and disasters. The widespread availability of smartphones has empowered individuals to swiftly report on emergencies they witness, fostering a sense of immediacy and connection within affected communities. Consequently, this surge in user-generated content has caught the attention of various organizations, particularly disaster relief agencies and news outlets, which are now keen on programmatically monitoring Twitter for pertinent information. However, pinpointing relevant tweets amidst the vast ocean of posts has proven challenging. The inherent ambiguity found in the linguistic structures of tweets often complicates the process, making it difficult to ascertain whether a user's message genuinely conveys information about a disaster or simply discusses unrelated topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset was obtained from Kaggle, which hosted a challenge named Real or Not. The primary objective of this challenge was to analyze Twitter data related to disaster tweets, which were originally curated by the company Figure-Eight. Participants in the challenge had the task of classifying these tweets into two distinct categories: those discussing actual disasters and those referencing disasters in a metaphorical or figurative context. This project aimed to enhance the understanding of public discourse surrounding disasters on social media.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Model for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using tinyBERT for this classification. BERT is designed to pre-train deep bidirectional representations from an unlabeled text by joint conditioning on the left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disaster or general tweet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/laxmimerit/All-CSV-ML-Data-Files-Download/master/twitter_disaster_tweets.csv\", usecols=['text', 'target'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Okay I need all of you to evacuate the house s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FREYAS VIDEO BLEW UP EVERYWHERE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im getting a car wow it hasn't sunk in</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@volcano_tornado live somewhere else for a whi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First Tweet collided with a Selfie. Pretty 'Sw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>Apparently they're going to have a WW2 siren t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>@Safyuan just a minor citation for possesion o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>i be on that hotboy shit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO)  ht...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>Still no plans? Don't worry we got you covered...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0     Okay I need all of you to evacuate the house s...       0\n",
       "1                       FREYAS VIDEO BLEW UP EVERYWHERE       0\n",
       "2                im getting a car wow it hasn't sunk in       0\n",
       "3     @volcano_tornado live somewhere else for a whi...       1\n",
       "4     First Tweet collided with a Selfie. Pretty 'Sw...       0\n",
       "...                                                 ...     ...\n",
       "7608  Apparently they're going to have a WW2 siren t...       0\n",
       "7609  @Safyuan just a minor citation for possesion o...       0\n",
       "7610                           i be on that hotboy shit       0\n",
       "7611  MEG issues Hazardous Weather Outlook (HWO)  ht...       1\n",
       "7612  Still no plans? Don't worry we got you covered...       0\n",
       "\n",
       "[7613 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# case, un-cased\n",
    "# context window -> 512 tokens\n",
    "# 1 token -> 3char\n",
    "\n",
    "df['text'].str.len().hist() #-> 160/3 => 53 => 60 tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data with Hugging Face Datasets Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'target': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Did anyone else see that fireball falling to earth? Look like a plane blew up.',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0:'general', 1: 'disaster'}\n",
    "label2id = {'general': 0, 'disaster': 1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using device:\", device)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model_ckpt = 'huawei-noah/TinyBERT_General_4L_312D'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7908b6d73bfc4dd180a167152f260f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6090 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089a303adfb047c0910e6d90d63e66f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1523 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer(dataset['train'][0]['text'])\n",
    "\n",
    "def tokenize(batch):\n",
    "    temp = tokenizer(batch['text'], padding=True, truncation=True, max_length=100)\n",
    "    return temp\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 6090\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1523\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model Evaluation Functions\n",
    "https://huggingface.co/docs/transformers/v4.42.0/en/tasks/sequence_classification#evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=len(label2id), label2id=label2id, id2label=id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install \"transformers[torch]\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install \"accelerate>=0.26.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/_1/m9h1bw2524zcxfmd013wvjq00000gn/T/ipykernel_27218/823868391.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir='train_dir',\n",
    "    overwrite_output_dir=True,\n",
    "    save_strategy='steps',            # Save checkpoints every few steps\n",
    "    save_steps=500,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy='epoch'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade numpy torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b9d832603941c38b4043e447b00c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/762 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3545f1f6931c455194ce579992a7e5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46462833881378174, 'eval_accuracy': 0.7957977675640184, 'eval_runtime': 13.4239, 'eval_samples_per_second': 113.454, 'eval_steps_per_second': 7.151, 'epoch': 1.0}\n",
      "{'loss': 0.4864, 'grad_norm': 5.231000900268555, 'learning_rate': 6.876640419947507e-06, 'epoch': 1.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27effc31f4e34d6192223958c597e92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.445855051279068, 'eval_accuracy': 0.8115561391989494, 'eval_runtime': 13.9782, 'eval_samples_per_second': 108.955, 'eval_steps_per_second': 6.868, 'epoch': 2.0}\n",
      "{'train_runtime': 513.6311, 'train_samples_per_second': 23.714, 'train_steps_per_second': 1.484, 'train_loss': 0.4661729166826864, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=762, training_loss=0.4661729166826864, metrics={'train_runtime': 513.6311, 'train_samples_per_second': 23.714, 'train_steps_per_second': 1.484, 'total_flos': 28653347298240.0, 'train_loss': 0.4661729166826864, 'epoch': 2.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960cf943b9fa42b2b4c3b15d8d74b38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.445855051279068,\n",
       " 'eval_accuracy': 0.8115561391989494,\n",
       " 'eval_runtime': 12.3354,\n",
       " 'eval_samples_per_second': 123.465,\n",
       " 'eval_steps_per_second': 7.782,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Save and Load for Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('tinybert-disaster-tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'disaster', 'score': 0.8643437027931213},\n",
       " {'label': 'general', 'score': 0.9056516885757446},\n",
       " {'label': 'general', 'score': 0.8909916281700134},\n",
       " {'label': 'general', 'score': 0.9037010073661804},\n",
       " {'label': 'disaster', 'score': 0.8668636083602905}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# data = ['this movie was horrible, the plot was really boring. acting was okay',\n",
    "#         'the movie is really sucked. there is not plot and acting was bad',\n",
    "#         'what a beautiful movie. great plot. acting was good. will see it again']\n",
    "\n",
    "data = ['There is a fire in the building', 'I am happy today', 'I am sad today', \n",
    "          'I am not feeling well','There is a flood in the city, go to higher ground']\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "classifier = pipeline('text-classification', model='tinybert-disaster-tweet', device=device)\n",
    "\n",
    "classifier(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push Model to AWS S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket is created\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket_name = 'mlops-oba'\n",
    "\n",
    "def create_bucket(bucket_name):\n",
    "    response = s3.list_buckets()\n",
    "    buckets = [buck['Name'] for buck in response['Buckets']]\n",
    "    if bucket_name not in buckets:\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "        print(\"Bucket is created\")\n",
    "\n",
    "    else:\n",
    "        print(\"Bucket already exists in your account!!! Feel free to use it.\")\n",
    "\n",
    "create_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded tinybert-disaster-tweet/model.safetensors to s3://mlops-oba/ml-models/tinybert-sentiment-analysis/model.safetensors\n",
      "Uploaded tinybert-disaster-tweet/tokenizer_config.json to s3://mlops-oba/ml-models/tinybert-sentiment-analysis/tokenizer_config.json\n",
      "Uploaded tinybert-disaster-tweet/special_tokens_map.json to s3://mlops-oba/ml-models/tinybert-sentiment-analysis/special_tokens_map.json\n",
      "Uploaded tinybert-disaster-tweet/config.json to s3://mlops-oba/ml-models/tinybert-sentiment-analysis/config.json\n",
      "Uploaded tinybert-disaster-tweet/tokenizer.json to s3://mlops-oba/ml-models/tinybert-sentiment-analysis/tokenizer.json\n",
      "Uploaded tinybert-disaster-tweet/training_args.bin to s3://mlops-oba/ml-models/tinybert-sentiment-analysis/training_args.bin\n",
      "Uploaded tinybert-disaster-tweet/vocab.txt to s3://mlops-oba/ml-models/tinybert-sentiment-analysis/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'mlops-oba'\n",
    "\n",
    "def upload_directory(directory_path, s3_prefix):\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            relpath = os.path.relpath(file_path, directory_path)\n",
    "            s3_key = os.path.join(s3_prefix, relpath)\n",
    "            \n",
    "            # Upload the file to S3\n",
    "            s3.upload_file(file_path, bucket_name, s3_key)\n",
    "            print(f\"Uploaded {file_path} to s3://{bucket_name}/{s3_key}\")\n",
    "\n",
    "# Start uploading the model folder to the specified S3 path\n",
    "upload_directory('tinybert-disaster-tweet', 'ml-models/tinybert-sentiment-analysis')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
